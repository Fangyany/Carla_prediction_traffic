{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "from importlib import import_module\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Sampler, DataLoader\n",
    "from utils import Logger, load_pretrain, gpu\n",
    "\n",
    "from CarlaDataset import CarlaDataset, from_numpy, worker_init_fn\n",
    "from Net import get_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "config = dict()\n",
    "config[\"epoch\"] = 10\n",
    "config[\"batch_size\"] = 32\n",
    "config[\"save_dir\"] = \"./weight_and_log_trafficLight\"\n",
    "config[\"save_freq\"] = 1\n",
    "config[\"num_epochs\"] = 36\n",
    "config[\"display_freq\"] = 10\n",
    "config[\"test_freq\"] = 1\n",
    "\n",
    "Dataset, collate_fn, net, loss, post_process, opt = get_model()\n",
    "\n",
    "# Data loader for training\n",
    "dataset = Dataset()\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 加载预训练权重\n",
    "# ckpt_path = ''\n",
    "# if not os.path.isabs(ckpt_path):\n",
    "#     ckpt_path = os.path.join(config[\"save_dir\"], ckpt_path)\n",
    "# ckpt = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "# load_pretrain(net, ckpt[\"state_dict\"])\n",
    "\n",
    "# config[\"epoch\"] = ckpt[\"epoch\"]\n",
    "# opt.load_state_dict(ckpt[\"opt_state\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* Validation, time 0.43 *************************\n",
      "loss 3.7832 0.2276 3.5556, ade1 0.5099, fde1 0.4542, ade 0.5099, fde 0.4542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# root_path = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "from pathlib import Path\n",
    "# Get the current notebook file path\n",
    "notebook_file_path = Path(os.path.abspath(\"\"))\n",
    "# Get the parent directory\n",
    "root_path = notebook_file_path.parent\n",
    "\n",
    "sys.path.insert(0, root_path)\n",
    "\n",
    "# Create log and copy all code\n",
    "save_dir = config[\"save_dir\"]\n",
    "log = os.path.join(save_dir, \"log\")\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "sys.stdout = Logger(log)\n",
    "\n",
    "src_dirs = [root_path]\n",
    "dst_dirs = [os.path.join(save_dir, \"files\")]\n",
    "for src_dir, dst_dir in zip(src_dirs, dst_dirs):\n",
    "    files = [f for f in os.listdir(src_dir) if f.endswith(\".py\")]\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "    for f in files:\n",
    "        shutil.copy(os.path.join(src_dir, f), os.path.join(dst_dir, f))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckpt(net, opt, save_dir, model_name, epoch):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    state_dict = net.state_dict()\n",
    "    for key in state_dict.keys():\n",
    "        state_dict[key] = state_dict[key].cpu()\n",
    "\n",
    "    save_name = model_name + \"%3.3f.ckpt\" % epoch\n",
    "    torch.save(\n",
    "        {\"epoch\": epoch, \"state_dict\": state_dict, \"opt_state\": opt.state_dict()},\n",
    "        os.path.join(save_dir, save_name),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_loader, net, loss, post_process, epoch):\n",
    "    net.eval()\n",
    "    start_time = time.time()\n",
    "    metrics = dict()\n",
    "    for i, data in enumerate(data_loader):\n",
    "        data = dict(data)\n",
    "        with torch.no_grad():\n",
    "            output = net(data)\n",
    "            loss_out = loss(output, data)\n",
    "            post_out = post_process(output, data)\n",
    "            post_process.append(metrics, loss_out, post_out)\n",
    "\n",
    "    dt = time.time() - start_time\n",
    "    # metrics = sync(metrics)\n",
    "    # if hvd.rank() == 0:\n",
    "    post_process.display(metrics, dt, epoch)\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, config, train_loader, net, loss, post_process, opt, val_loader=None):\n",
    "    net.train()\n",
    "    num_batches = len(train_loader)\n",
    "    epoch_per_batch = 1.0 / num_batches\n",
    "    save_iters = int(np.ceil(config[\"save_freq\"] * num_batches))\n",
    "    display_iters = int(np.ceil(config[\"display_freq\"] * num_batches))\n",
    "    test_iters = int(np.ceil(config[\"test_freq\"] * num_batches))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    metrics = dict()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        epoch += epoch_per_batch\n",
    "        output = net(data)\n",
    "        \n",
    "        loss_out = loss(output, data)\n",
    "        post_out = post_process(output, data)\n",
    "        post_process.append(metrics, loss_out, post_out)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss_out[\"loss\"].backward()\n",
    "        lr = opt.step(epoch)\n",
    "\n",
    "        num_iters = int(np.round(epoch * num_batches))\n",
    "        if num_iters % save_iters == 0 or epoch >= config[\"num_epochs\"]:\n",
    "            save_ckpt(net, opt, config[\"save_dir\"], \"net\", epoch)\n",
    "\n",
    "        if num_iters % display_iters == 0:\n",
    "            dt = time.time() - start_time\n",
    "            # metrics = sync(metrics)\n",
    "            post_process.display(metrics, dt, epoch, lr)\n",
    "            start_time = time.time()\n",
    "            metrics = dict()\n",
    "\n",
    "        if num_iters % test_iters == 0:\n",
    "            test(val_loader, net, loss, post_process, epoch)\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = config[\"epoch\"]\n",
    "remaining_epochs = int(np.ceil(config[\"num_epochs\"] - epoch))\n",
    "for i in range(remaining_epochs):\n",
    "    train(epoch + i, config, train_loader, net, loss, post_process, opt, test_loader)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
